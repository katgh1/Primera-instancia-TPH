{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"16Ia4TD-CErZs8HkXSJprZu9ehKBi_nEG","timestamp":1750912013839}]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Introducción a la generación de descripciones de imágenes con IA"],"metadata":{"id":"DiJ_GcY233mq"}},{"cell_type":"markdown","source":["Propósito general:\n","\n","Este cuaderno tiene como objetivo introducir a personas sin experiencia previa en el uso de la IA para la generación automática de descripciones de imágenes. A través de un ejemplo práctico, aprenderás a utilizar la biblioteca transformers de Hugging Face para cargar un modelo pre-entrenado, procesar una imagen y generar una descripción textual de la misma.\n","\n","En este cuaderno, se abordarán los siguientes temas:\n","\n","* Instalación de la biblioteca transformers: Se explicará cómo instalar la biblioteca transformers y sus dependencias necesarias en Google Colab.\n","\n","* Carga del modelo y procesador: Aprenderás a cargar un modelo pre-entrenado de Hugging Face, específicamente el modelo \"Salesforce/blip-image-captioning-base\", junto con su procesador correspondiente.\n","\n","* Carga y preparación de la imagen: Se te guiará en el proceso de cargar una imagen en el cuaderno y prepararla para ser procesada por el modelo.\n","\n","* Generación de la descripción: Verás cómo utilizar el modelo para generar una descripción textual de la imagen cargada.\n","\n","* Visualización de la descripción: Finalmente, se mostrará cómo imprimir la descripción generada por el modelo.\n","\n","\n","*   Elemento de lista\n","\n"],"metadata":{"id":"S-0CuULE4BM8"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"3R0wVA0VyKa5"},"outputs":[],"source":["# Install the transformers library\n","!pip install transformers Pillow torch torchvision torchaudio -q\n","from transformers import BlipProcessor, BlipForConditionalGeneration\n","from PIL import Image"]},{"cell_type":"code","source":["# Initialize the processor and model from Hugging Face\n","processor = BlipProcessor.from_pretrained(\"Salesforce/blip-image-captioning-base\")\n","model = BlipForConditionalGeneration.from_pretrained(\"Salesforce/blip-image-captioning-base\")"],"metadata":{"id":"8zSdUwSczBWg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Load an image\n","image = Image.open(\"/content/istockphoto-1403073162-612x612.jpg\")"],"metadata":{"id":"d3hH9pzezHKy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Prepare the image\n","inputs = processor(image, return_tensors=\"pt\")"],"metadata":{"id":"5CD4r8JR0S64"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Generate captions\n","outputs = model.generate(**inputs)\n","caption = processor.decode(outputs[0],skip_special_tokens=True)"],"metadata":{"id":"xwKmLxDm0S0H"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(\"Generated Caption:\", caption)"],"metadata":{"id":"l7VohmTY0Sr5"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Interfaz interactiva con Gradio"],"metadata":{"id":"R5os-8V674K9"}},{"cell_type":"markdown","source":["En esta sección, se implementa una interfaz de usuario interactiva utilizando la biblioteca Gradio. Esta interfaz permite a los usuarios cargar sus propias imágenes y obtener descripciones generadas por el modelo BLIP de manera sencilla e intuitiva, sin necesidad de escribir código."],"metadata":{"id":"SbxP5Ouc78Kq"}},{"cell_type":"code","source":["!pip install gradio -q"],"metadata":{"id":"FyXbI86b4drs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import gradio as gr"],"metadata":{"id":"d8jpLcTP4hV9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def generar_descripcion(imagen):\n","    # Ahora usando directamente el objeto PIL Image\n","    entradas = processor(images=imagen, return_tensors=\"pt\")\n","    salidas = model.generate(**entradas)\n","    descripcion = processor.decode(salidas[0], skip_special_tokens=True)\n","    return descripcion"],"metadata":{"id":"aNfUZBSW6--m"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def descripcion_imagen(imagen):\n","    \"\"\"\n","    Recibe una imagen PIL y devuelve una descripción.\n","    \"\"\"\n","    try:\n","        descripcion = generar_descripcion(imagen)\n","        return descripcion\n","    except Exception as e:\n","        return f\"Ocurrió un error: {str(e)}\""],"metadata":{"id":"90-UjKH46-0E"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["interfaz = gr.Interface(\n","    fn=descripcion_imagen,\n","    inputs=gr.Image(type=\"pil\"),\n","    outputs=\"text\",\n","    title=\"Generación de descripciones de imágenes con BLIP\",\n","    description=\"Sube una imagen para generar una descripción.\"\n",")\n","interfaz.launch()"],"metadata":{"id":"U2IscFC44vIe"},"execution_count":null,"outputs":[]}]}